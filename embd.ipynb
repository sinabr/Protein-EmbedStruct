{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf4da63",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import esm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Paths\n",
    "df_path = Path(\"pdb_mutant_pairs/pairs_analysis_summary.csv\")\n",
    "root_dir = Path(\"pdb_mutant_pairs\")\n",
    "\n",
    "# Load metadata\n",
    "meta = pd.read_csv(df_path)\n",
    "\n",
    "# Gather sequence pairs\n",
    "import re\n",
    "\n",
    "def load_sequence(pair_name):\n",
    "    pair_dir = root_dir / pair_name\n",
    "    fasta_files = list(pair_dir.glob(\"*.fasta\"))\n",
    "    if len(fasta_files) != 2:\n",
    "        raise ValueError(f\"Expected 2 FASTA files in {pair_dir}, found {len(fasta_files)}\")\n",
    "    seqs = []\n",
    "    for fasta in fasta_files:\n",
    "        with open(fasta) as f:\n",
    "            lines = [l.strip() for l in f if not l.startswith('>')]\n",
    "        seq = ''.join(lines)\n",
    "        # Uppercase and filter to valid amino acids\n",
    "        seq = seq.upper()\n",
    "        seq = re.sub(r'[^ACDEFGHIKLMNPQRSTVWY]', '', seq)\n",
    "        if not seq:\n",
    "            raise ValueError(f\"No valid amino acids in sequence from {fasta}\")\n",
    "        seqs.append(seq)\n",
    "    if len(seqs[0]) != len(seqs[1]):\n",
    "        raise ValueError(f\"Sequence length mismatch in {pair_name}\")\n",
    "    return seqs\n",
    "\n",
    "pairs = []\n",
    "for _, row in meta.iterrows():\n",
    "    name = row['pair']\n",
    "    try:\n",
    "        seq1, seq2 = load_sequence(name)\n",
    "    except Exception:\n",
    "        continue\n",
    "    pairs.append({\n",
    "        'pair': name,\n",
    "        'seq1': seq1,\n",
    "        'seq2': seq2,\n",
    "        'rmsd': row['rmsd'],\n",
    "        'mutations': row['mutations'],\n",
    "        'identity_pct': row['identity_pct']\n",
    "    })\n",
    "\n",
    "# Load ESM-2 model\n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "model = model.to(device).eval()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "# Embed unique sequences\n",
    "unique_seqs = list({p['seq1'] for p in pairs} | {p['seq2'] for p in pairs})\n",
    "embeddings = {}\n",
    "batch_size = 32\n",
    "for i in range(0, len(unique_seqs), batch_size):\n",
    "    batch = unique_seqs[i:i+batch_size]\n",
    "    # Prepare batch for conversion: (label, seq)\n",
    "    raw_batch = [(str(idx), seq) for idx, seq in enumerate(batch)]\n",
    "    labels, seq_strs, tokens = batch_converter(raw_batch)\n",
    "    with torch.no_grad():\n",
    "        results = model(tokens.to(device), repr_layers=[model.num_layers], return_contacts=False)\n",
    "    reps = results['representations'][model.num_layers]\n",
    "    for j, seq in enumerate(batch):\n",
    "        length = len(seq)\n",
    "        emb = reps[j, 1: length+1].mean(0).cpu().numpy()\n",
    "        embeddings[seq] = emb\n",
    "\n",
    "# Compute embedding distances\n",
    "cosines, euclids = [], []\n",
    "for p in pairs:\n",
    "    print(f\"Processing pair {p['pair']}\")\n",
    "    e1, e2 = embeddings[p['seq1']], embeddings[p['seq2']]\n",
    "    cosines.append(cosine_distances([e1], [e2])[0,0])\n",
    "    euclids.append(euclidean_distances([e1], [e2])[0,0])\n",
    "meta['embed_cosine'] = cosines\n",
    "meta['embed_euclid'] = euclids\n",
    "\n",
    "# Correlation analysis\n",
    "corrs = {\n",
    "    'cosine_vs_rmsd': np.corrcoef(meta['embed_cosine'], meta['rmsd'])[0,1],\n",
    "    'cosine_vs_mut': np.corrcoef(meta['embed_cosine'], meta['mutations'])[0,1],\n",
    "    'euclid_vs_rmsd': np.corrcoef(meta['embed_euclid'], meta['rmsd'])[0,1],\n",
    "    'euclid_vs_mut': np.corrcoef(meta['embed_euclid'], meta['mutations'])[0,1]\n",
    "}\n",
    "print(\"Embedding-to-metric correlations:\", corrs)\n",
    "\n",
    "# PCA disentanglement\n",
    "diffs = np.stack([embeddings[p['seq1']] - embeddings[p['seq2']] for p in pairs])\n",
    "pca = PCA(n_components=5)\n",
    "pcs = pca.fit_transform(diffs)\n",
    "results = []\n",
    "for idx in range(pcs.shape[1]):\n",
    "    pc = pcs[:, idx]\n",
    "    results.append({\n",
    "        'PC': idx+1,\n",
    "        'explained_variance': pca.explained_variance_ratio_[idx],\n",
    "        'corr_rmsd': np.corrcoef(pc, meta['rmsd'])[0,1],\n",
    "        'corr_mut': np.corrcoef(pc, meta['mutations'])[0,1]\n",
    "    })\n",
    "df_pca = pd.DataFrame(results)\n",
    "print(\"\\nPCA Disentanglement:\")\n",
    "print(df_pca)\n",
    "\n",
    "# Save outputs\n",
    "meta.to_csv(root_dir / 'pairs_embedding_analysis.csv', index=False)\n",
    "df_pca.to_csv(root_dir / 'pairs_pca_disentanglement.csv', index=False)\n",
    "print(\"Results saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab5869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.mps.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
