{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e9409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 proteins...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "UNIPROT_API = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "PFAM_API = \"https://pfam.xfam.org/protein/\"\n",
    "RCSB_API = \"https://search.rcsb.org/rcsbsearch/v2/query\"\n",
    "OUTPUT_DIR = \"protein_sequences\"\n",
    "BATCH_SIZE = 100\n",
    "MAX_PROTEINS = 500\n",
    "RETRY_LIMIT = 3\n",
    "DELAY = 1\n",
    "USE_XRAY = True  # Set to False to skip X-ray filtering\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "def query_uniprot(query, size=100):\n",
    "    \"\"\"Query UniProt API and return protein entries.\"\"\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"json\",\n",
    "        \"size\": size,\n",
    "        \"fields\": \"accession,id,sequence,ft_domain,cc_domain\"\n",
    "    }\n",
    "    for attempt in range(RETRY_LIMIT):\n",
    "        try:\n",
    "            response = requests.get(UNIPROT_API, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get(\"results\", [])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"UniProt query failed (attempt {attempt + 1}): {e}\")\n",
    "            time.sleep(DELAY * (attempt + 1))\n",
    "    return []\n",
    "\n",
    "def query_rcsb_xray():\n",
    "    \"\"\"Query RCSB PDB for X-ray structures of human proteins.\"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"type\": \"group\",\n",
    "            \"logical_operator\": \"and\",\n",
    "            \"nodes\": [\n",
    "                {\n",
    "                    \"type\": \"terminal\",\n",
    "                    \"service\": \"text\",\n",
    "                    \"parameters\": {\n",
    "                        \"attribute\": \"rcsb_entity_source_organism.taxonomy_lineage.name\",\n",
    "                        \"operator\": \"exact_match\",\n",
    "                        \"value\": \"Homo sapiens\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"terminal\",\n",
    "                    \"service\": \"text\",\n",
    "                    \"parameters\": {\n",
    "                        \"attribute\": \"exptl.method\",\n",
    "                        \"operator\": \"exact_match\",\n",
    "                        \"value\": \"X-RAY DIFFRACTION\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"return_type\": \"entry\",\n",
    "        \"request_options\": {\n",
    "            \"return_all_hits\": True\n",
    "        }\n",
    "    }\n",
    "    for attempt in range(RETRY_LIMIT):\n",
    "        try:\n",
    "            response = requests.post(RCSB_API, json=query)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get(\"result_set\", [])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"RCSB query failed (attempt {attempt + 1}): {e}\")\n",
    "            time.sleep(DELAY * (attempt + 1))\n",
    "    return []\n",
    "\n",
    "def get_pfam_domains(uniprot_id):\n",
    "    \"\"\"Fetch Pfam domains for a UniProt ID.\"\"\"\n",
    "    url = f\"{PFAM_API}{uniprot_id}/entry\"\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "    for attempt in range(RETRY_LIMIT):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            return [entry[\"accession\"] for entry in data.get(\"entry\", {}).get(\"regions\", [])]\n",
    "        except (requests.exceptions.RequestException, ValueError) as e:\n",
    "            print(f\"Pfam query failed for {uniprot_id} (attempt {attempt + 1}): {e}\")\n",
    "            time.sleep(DELAY * (attempt + 1))\n",
    "    return []\n",
    "\n",
    "def map_pdb_to_uniprot(pdb_id):\n",
    "    \"\"\"Map PDB ID to UniProt ID.\"\"\"\n",
    "    url = f\"https://data.rcsb.org/rest/v1/core/entry/{pdb_id}\"\n",
    "    for attempt in range(RETRY_LIMIT):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            uniprot_ids = []\n",
    "            for entity in data.get(\"rcsb_entry_container_identifiers\", {}).get(\"polymer_entity_ids\", []):\n",
    "                entity_url = f\"https://data.rcsb.org/rest/v1/core/polymer_entity/{pdb_id}/{entity}\"\n",
    "                entity_response = requests.get(entity_url)\n",
    "                entity_response.raise_for_status()\n",
    "                entity_data = entity_response.json()\n",
    "                for ref in entity_data.get(\"rcsb_polymer_entity_container_identifiers\", {}).get(\"uniprot_ids\", []):\n",
    "                    uniprot_ids.append(ref)\n",
    "            return uniprot_ids\n",
    "        except (requests.exceptions.RequestException, ValueError) as e:\n",
    "            print(f\"PDB to UniProt mapping failed for {pdb_id} (attempt {attempt + 1}): {e}\")\n",
    "            time.sleep(DELAY * (attempt + 1))\n",
    "    return []\n",
    "\n",
    "def classify_proteins(proteins, xray_uniprot_ids=None):\n",
    "    \"\"\"Classify proteins into single-domain, multi-domain, and shared-domain pairs.\"\"\"\n",
    "    protein_domains = []\n",
    "    for protein in proteins:\n",
    "        uniprot_id = protein[\"primaryAccession\"]\n",
    "        if xray_uniprot_ids and uniprot_id not in xray_uniprot_ids:\n",
    "            continue  # Skip proteins without X-ray structures if USE_XRAY is True\n",
    "        domains = get_pfam_domains(uniprot_id)\n",
    "        if domains:\n",
    "            protein_domains.append({\n",
    "                \"uniprot_id\": uniprot_id,\n",
    "                \"sequence\": protein[\"sequence\"][\"value\"],\n",
    "                \"domains\": domains\n",
    "            })\n",
    "        time.sleep(DELAY)\n",
    "\n",
    "    # Classify proteins\n",
    "    single_domain = [p for p in protein_domains if len(p[\"domains\"]) == 1]\n",
    "    multi_domain = [p for p in protein_domains if len(p[\"domains\"]) >= 2]\n",
    "\n",
    "    # Find multi-domain proteins with shared domains\n",
    "    domain_to_proteins = defaultdict(list)\n",
    "    for protein in multi_domain:\n",
    "        for domain in protein[\"domains\"]:\n",
    "            domain_to_proteins[domain].append(protein)\n",
    "\n",
    "    shared_domain_proteins = []\n",
    "    for domain, proteins in domain_to_proteins.items():\n",
    "        if len(proteins) > 1:\n",
    "            for i, p1 in enumerate(proteins):\n",
    "                for p2 in proteins[i + 1:]:\n",
    "                    if p1[\"domains\"] != p2[\"domains\"]:\n",
    "                        shared_domain_proteins.append((p1, p2))\n",
    "\n",
    "    return single_domain, multi_domain, shared_domain_proteins\n",
    "\n",
    "def find_mutant_pairs(shared_domain_proteins):\n",
    "    \"\"\"Identify pairs with potential mutations (sequence differences in shared domains).\"\"\"\n",
    "    mutant_pairs = []\n",
    "    for p1, p2 in shared_domain_proteins:\n",
    "        seq1, seq2 = p1[\"sequence\"], p2[\"sequence\"]\n",
    "        shared_domains = set(p1[\"domains\"]) & set(p2[\"domains\"])\n",
    "        if len(seq1) == len(seq2):  # Simple check for sequence differences\n",
    "            differences = sum(a != b for a, b in zip(seq1, seq2))\n",
    "            if 0 < differences < 10:  # Arbitrary threshold for \"mutant\" (adjust as needed)\n",
    "                mutant_pairs.append((p1, p2))\n",
    "    return mutant_pairs\n",
    "\n",
    "def save_fasta(proteins, filename, description_prefix):\n",
    "    \"\"\"Save protein sequences to a FASTA file.\"\"\"\n",
    "    records = []\n",
    "    for protein in proteins:\n",
    "        uniprot_id = protein[\"uniprot_id\"]\n",
    "        seq = Seq(protein[\"sequence\"])\n",
    "        domains = \",\".join(protein[\"domains\"])\n",
    "        record = SeqRecord(\n",
    "            seq,\n",
    "            id=uniprot_id,\n",
    "            description=f\"{description_prefix} | Domains: {domains}\"\n",
    "        )\n",
    "        records.append(record)\n",
    "\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        SeqIO.write(records, f, \"fasta\")\n",
    "    print(f\"Saved {len(records)} sequences to {filepath}\")\n",
    "\n",
    "def save_shared_domain_fasta(pairs, filename, prefix=\"SharedDomain\"):\n",
    "    \"\"\"Save pairs of proteins to a FASTA file.\"\"\"\n",
    "    records = []\n",
    "    for p1, p2 in pairs:\n",
    "        for protein, idx in [(p1, 1), (p2, 2)]:\n",
    "            uniprot_id = protein[\"uniprot_id\"]\n",
    "            seq = Seq(protein[\"sequence\"])\n",
    "            domains = \",\".join(protein[\"domains\"])\n",
    "            record = SeqRecord(\n",
    "                seq,\n",
    "                id=uniprot_id,\n",
    "                description=f\"{prefix}_Pair{idx} | Domains: {domains}\"\n",
    "            )\n",
    "            records.append(record)\n",
    "\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        SeqIO.write(records, f, \"fasta\")\n",
    "    print(f\"Saved {len(records)} sequences to {filepath}\")\n",
    "\n",
    "def main():\n",
    "    # Query human proteins\n",
    "    query = \"organism_id:9606 reviewed:true\"\n",
    "    proteins = query_uniprot(query, size=BATCH_SIZE)\n",
    "    if not proteins:\n",
    "        print(\"No proteins retrieved from UniProt.\")\n",
    "        return\n",
    "\n",
    "    # Limit to MAX_PROTEINS\n",
    "    proteins = proteins[:MAX_PROTEINS]\n",
    "    print(f\"Processing {len(proteins)} proteins...\")\n",
    "\n",
    "    # Optionally filter for X-ray structures\n",
    "    xray_uniprot_ids = None\n",
    "    if USE_XRAY:\n",
    "        xray_entries = query_rcsb_xray()\n",
    "        xray_uniprot_ids = set()\n",
    "        for entry in xray_entries:\n",
    "            pdb_id = entry[\"identifier\"]\n",
    "            uniprot_ids = map_pdb_to_uniprot(pdb_id)\n",
    "            xray_uniprot_ids.update(uniprot_ids)\n",
    "        print(f\"Found {len(xray_uniprot_ids)} UniProt IDs with X-ray structures\")\n",
    "\n",
    "    # Classify proteins\n",
    "    single_domain, multi_domain, shared_domain_proteins = classify_proteins(proteins, xray_uniprot_ids)\n",
    "\n",
    "    # Find mutant pairs (if needed)\n",
    "    mutant_pairs = find_mutant_pairs(shared_domain_proteins)\n",
    "\n",
    "    # Save sequences\n",
    "    save_fasta(single_domain, \"single_domain.fasta\", \"SingleDomain\")\n",
    "    save_fasta(multi_domain, \"multi_domain.fasta\", \"MultiDomain\")\n",
    "    save_shared_domain_fasta(shared_domain_proteins, \"shared_domain_pairs.fasta\")\n",
    "    save_shared_domain_fasta(mutant_pairs, \"mutant_pairs.fasta\", prefix=\"Mutant\")\n",
    "\n",
    "    # Summary\n",
    "    print(f\"Single-domain proteins: {len(single_domain)}\")\n",
    "    print(f\"Multi-domain proteins: {len(multi_domain)}\")\n",
    "    print(f\"Shared domain protein pairs: {len(shared_domain_proteins)}\")\n",
    "    print(f\"Mutant pairs: {len(mutant_pairs)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
